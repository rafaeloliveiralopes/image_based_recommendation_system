{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !kaggle datasets download -d paramaggarwal/fashion-product-images-small\n",
        "# !unzip fashion-product-images-small.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF version: 2.18.0\n",
            "Hub version: 0.16.1\n",
            "GPU is available\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import itertools\n",
        "from pathlib import Path\n",
        "from shutil import move\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Extensão do tqdm para DataFrames\n",
        "tqdm.pandas()\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparação de diretórios e organização das imagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar pasta principal\n",
        "data_dir = 'Fashion_data'\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "# Ler o CSV\n",
        "df = pd.read_csv('styles.csv', usecols=['id', 'masterCategory'])\n",
        "df['id'] = df['id'].astype(str)\n",
        "\n",
        "# Mover imagens para subpastas de categoria\n",
        "images_source = 'images'\n",
        "categories_dir = os.path.join(data_dir, 'categories')\n",
        "\n",
        "# Criar diretório de categorias se não existir\n",
        "os.makedirs(categories_dir, exist_ok=True)\n",
        "\n",
        "# Processar cada imagem\n",
        "all_images = os.listdir(images_source)\n",
        "moved_count = 0\n",
        "\n",
        "for image in tqdm(all_images):\n",
        "    image_id = image.split('.')[0]\n",
        "    category = df.loc[df['id'] == image_id, 'masterCategory'].values\n",
        "    \n",
        "    if len(category) == 0:\n",
        "        continue  # Pula se a categoria não for encontrada\n",
        "    \n",
        "    category = category[0]\n",
        "    category_path = os.path.join(categories_dir, category)\n",
        "    \n",
        "    # Criar subpasta da categoria se necessário\n",
        "    os.makedirs(category_path, exist_ok=True)\n",
        "    \n",
        "    # Mover a imagem\n",
        "    src = os.path.join(images_source, image)\n",
        "    dst = os.path.join(category_path, image)\n",
        "    move(src, dst)\n",
        "    moved_count += 1\n",
        "\n",
        "print(f'Total de imagens movidas: {moved_count}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Definição de parâmetros e modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1740083226.680205   16148 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2795 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ hub_wrapper (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">HubWrapper</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6144</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6144</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,573,120</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ hub_wrapper (\u001b[38;5;33mHubWrapper\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6144\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6144\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m1,573,120\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m1,799\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,919</span> (6.01 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,574,919\u001b[0m (6.01 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,919</span> (6.01 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,574,919\u001b[0m (6.01 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "MODULE_HANDLE = \"https://tfhub.dev/google/bit/m-r50x3/1\"\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "N_FEATURES = 256\n",
        "\n",
        "# Classe de encapsulamento do hub.KerasLayer\n",
        "class HubWrapper(tf.keras.layers.Layer):\n",
        "    def __init__(self, module_handle, trainable=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        # Define uma camada do TF Hub\n",
        "        self.hub_layer = hub.KerasLayer(module_handle, trainable=trainable)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Encaminha os dados de entrada para a camada do Hub\n",
        "        return self.hub_layer(inputs)\n",
        "\n",
        "# Construção do modelo Sequential\n",
        "model = tf.keras.Sequential([\n",
        "    # Camada de entrada\n",
        "    tf.keras.layers.Input(shape=IMAGE_SIZE + (3,)),\n",
        "    \n",
        "    # Envolve a camada do TensorFlow Hub no wrapper personalizado\n",
        "    HubWrapper(MODULE_HANDLE, trainable=False),\n",
        "    \n",
        "    # Camada de Dropout para reduzir overfitting\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    \n",
        "    # Camada densa intermediária\n",
        "    tf.keras.layers.Dense(\n",
        "        N_FEATURES,\n",
        "        kernel_regularizer=tf.keras.regularizers.l2(0.0001)\n",
        "    ),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    \n",
        "    # Camada de saída com 7 neurônios, pois temos 7 classes\n",
        "    tf.keras.layers.Dense(\n",
        "        7,  # Ajustado para 7 classes\n",
        "        kernel_regularizer=tf.keras.regularizers.l2(0.0001)\n",
        "    )\n",
        "])\n",
        "\n",
        "# Constrói formalmente o modelo (opcional, mas útil para summary)\n",
        "model.build((None,) + IMAGE_SIZE + (3,))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparação dos geradores de dados(treino/validação)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8886 images belonging to 7 classes.\n",
            "Found 35555 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "data_dir = 'Fashion_data/categories'\n",
        "\n",
        "# Normalização e separação (20% para validação)\n",
        "datagen_kwargs = dict(rescale=1./255, validation_split=0.20)\n",
        "\n",
        "# Parâmetros para o fluxo de dados\n",
        "dataflow_kwargs = dict(\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    interpolation=\"bilinear\"\n",
        ")\n",
        "\n",
        "# Gerador de dados para o conjunto de validação\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    subset=\"validation\",\n",
        "    shuffle=False,\n",
        "    **dataflow_kwargs\n",
        ")\n",
        "\n",
        "# Gerador de dados para treinamento\n",
        "# Define se vamos utilizar data augmentation\n",
        "do_data_augmentation = False\n",
        "if do_data_augmentation:\n",
        "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        horizontal_flip=True,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        **datagen_kwargs\n",
        "    )\n",
        "else:\n",
        "    train_datagen = valid_datagen\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    subset=\"training\",\n",
        "    shuffle=True,\n",
        "    **dataflow_kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compilação e treinamento do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rafael/Desafios/image_based_recommendation_system/image-based-recommendation/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1740083277.711043   16908 service.cc:148] XLA service 0x7f004c00b9d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1740083277.711214   16908 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
            "2025-02-20 17:27:58.194533: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1740083280.349265   16908 cuda_dnn.cc:529] Loaded cuDNN version 90600\n",
            "2025-02-20 17:28:01.445832: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 1s:\n",
            "\n",
            "  %multiply.277 = f32[32,224,224,3]{3,2,1,0} multiply(f32[32,224,224,3]{3,2,1,0} %broadcast.276, f32[32,224,224,3]{3,2,1,0} %constant.275), metadata={op_type=\"Mul\" op_name=\"sequential_1/hub_wrapper_1/keras_layer/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/mul_0\" source_file=\"dummy_file_name\" source_line=10}\n",
            "\n",
            "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
            "\n",
            "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
            "2025-02-20 17:28:02.520681: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.074922757s\n",
            "Constant folding an instruction is taking > 1s:\n",
            "\n",
            "  %multiply.277 = f32[32,224,224,3]{3,2,1,0} multiply(f32[32,224,224,3]{3,2,1,0} %broadcast.276, f32[32,224,224,3]{3,2,1,0} %constant.275), metadata={op_type=\"Mul\" op_name=\"sequential_1/hub_wrapper_1/keras_layer/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/mul_0\" source_file=\"dummy_file_name\" source_line=10}\n",
            "\n",
            "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
            "\n",
            "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
            "2025-02-20 17:28:04.520881: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 2s:\n",
            "\n",
            "  %add.147 = f32[32,224,224,3]{3,2,1,0} add(f32[32,224,224,3]{3,2,1,0} %constant.449, f32[32,224,224,3]{3,2,1,0} %broadcast.274), metadata={op_type=\"Sub\" op_name=\"sequential_1/hub_wrapper_1/keras_layer/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/sub\" source_file=\"dummy_file_name\" source_line=10}\n",
            "\n",
            "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
            "\n",
            "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
            "2025-02-20 17:28:04.873543: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.352754013s\n",
            "Constant folding an instruction is taking > 2s:\n",
            "\n",
            "  %add.147 = f32[32,224,224,3]{3,2,1,0} add(f32[32,224,224,3]{3,2,1,0} %constant.449, f32[32,224,224,3]{3,2,1,0} %broadcast.274), metadata={op_type=\"Sub\" op_name=\"sequential_1/hub_wrapper_1/keras_layer/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/sub\" source_file=\"dummy_file_name\" source_line=10}\n",
            "\n",
            "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
            "\n",
            "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
            "2025-02-20 17:28:26.801951: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.37GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2025-02-20 17:28:28.297274: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.85GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2025-02-20 17:28:28.899961: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.85GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2025-02-20 17:28:29.552888: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.43GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2025-02-20 17:28:31.011652: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 10.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2025-02-20 17:28:34.582085: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.90GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2025-02-20 17:28:35.308886: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.20GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2025-02-20 17:28:38.511179: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 9.98GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2025-02-20 17:28:39.809096: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.61GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2025-02-20 17:28:42.113876: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "I0000 00:00:1740083336.176304   16908 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m   3/1111\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:44:02\u001b[0m 35s/step - accuracy: 0.1059 - loss: 3.8303"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "# Treina o modelo\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=valid_generator.samples // BATCH_SIZE,\n",
        "    epochs=EPOCHS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPUs disponíveis: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "print(\"GPUs disponíveis:\", tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOIVmDHEZ/zfB8jGn9gDPpR",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "image-based-recommendation",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
